{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba6a086",
   "metadata": {},
   "source": [
    "# GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22656df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ---------- LlamaIndex (índices) ----------\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.core.indices.knowledge_graph import KnowledgeGraphIndex\n",
    "from llama_index.core.indices.list.base import SummaryIndex\n",
    "from llama_index.core.composability import ComposableGraph\n",
    "from llama_index.graph_stores.neo4j import Neo4jGraphStore\n",
    "from llama_index.llms.openai import OpenAI as LI_OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# ---------- LangGraph / LangChain (agente) ----------\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import PyMuPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54286803",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "NEO4J_URL = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "PDF_DIR = \"../data/docs\"\n",
    "\n",
    "# Modelos OpenAI (ajusta si quieres)\n",
    "# LlamaIndex (para extracción KG/embeddings) puede usar modelos “baratos”\n",
    "LI_LLM_MODEL = \"gpt-4o-mini\"          # para LlamaIndex internamente\n",
    "EMBED_MODEL = \"text-embedding-3-small\" # embeddings\n",
    "# El agente (LangGraph) puede usar un modelo distinto si quieres\n",
    "AGENT_LLM_MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_indices():\n",
    "    # ---------- Config global de LlamaIndex ----------\n",
    "    Settings.llm = LI_OpenAI(model=LI_LLM_MODEL, temperature=0)\n",
    "    Settings.embed_model = OpenAIEmbedding(model=EMBED_MODEL)\n",
    "\n",
    "    # ---------- 1) PDFs → documentos ----------\n",
    "    docs = SimpleDirectoryReader(input_dir=PDF_DIR).load_data()\n",
    "    if not docs:\n",
    "        raise RuntimeError(f\"No se encontraron PDFs en: {PDF_DIR}\")\n",
    "\n",
    "    # ---------- 2) Grafo en Neo4j ----------\n",
    "    graph_store = Neo4jGraphStore(\n",
    "        url=NEO4J_URL, username=NEO4J_USER, password=NEO4J_PASSWORD\n",
    "    )\n",
    "\n",
    "    # ---------- 3) Construir KG (tripletas → Neo4j) ----------\n",
    "    kg_index = KnowledgeGraphIndex.from_documents(\n",
    "        docs,\n",
    "        graph_store=graph_store,\n",
    "        max_triplets_per_chunk=3,\n",
    "    )\n",
    "\n",
    "    # ---------- 4) Vector index ----------\n",
    "    vec_index = VectorStoreIndex.from_documents(docs)\n",
    "\n",
    "    # ---------- 5) Composición híbrida ----------\n",
    "    composed = ComposableGraph.from_indices(\n",
    "        root_index_cls=SummaryIndex,\n",
    "        children_indices=[kg_index, vec_index],\n",
    "        index_summaries=[\n",
    "            \"Knowledge Graph: entidades y relaciones del corpus; útil para preguntas relacionales y de conexiones.\",\n",
    "            \"Vector Index: pasajes textuales exactos del PDF; útil para definiciones, fórmulas y citas literales.\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return kg_index, vec_index, composed\n",
    "\n",
    "\n",
    "def build_tools(kg_index, vec_index, composed):\n",
    "    # Motores de consulta independientes\n",
    "    kg_engine = kg_index.as_query_engine()                 # centrado en grafo (entidades/relaciones)\n",
    "    vec_engine = vec_index.as_query_engine(similarity_top_k=4)  # centrado en pasajes\n",
    "    cmp_engine = composed.as_query_engine()                # híbrido (usa la jerarquía root+children)\n",
    "\n",
    "    @tool\n",
    "    def graph_search(query: str) -> str:\n",
    "        \"\"\"Devuelve hechos/relaciones extraídos desde el grafo (Neo4j).\"\"\"\n",
    "        print(\"Graph search query:\", query)\n",
    "        result = str(kg_engine.query(query))\n",
    "        print(\"Graph search result:\", result)\n",
    "        return result\n",
    "\n",
    "    @tool\n",
    "    def vector_search(query: str) -> str:\n",
    "        \"\"\"Devuelve pasajes textuales relevantes desde el índice vectorial.\"\"\"\n",
    "        print(\"Vector search query:\", query)\n",
    "        result = str(vec_engine.query(query))\n",
    "        print(\"Vector search result:\", result)\n",
    "        return result\n",
    "\n",
    "    @tool\n",
    "    def hybrid_search(query: str) -> str:\n",
    "        \"\"\"Combina señales de grafo y texto para un contexto más completo.\"\"\"\n",
    "        print(\"Hybrid search query:\", query)\n",
    "        result = str(cmp_engine.query(query))\n",
    "        print(\"Hybrid search result:\", result)\n",
    "        return result\n",
    "\n",
    "    return [graph_search, vector_search, hybrid_search]\n",
    "\n",
    "\n",
    "def build_agent(tools):\n",
    "    # LLM del agente (LangGraph / LangChain)\n",
    "    llm = ChatOpenAI(model=AGENT_LLM_MODEL, temperature=0)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Eres un agente GraphRAG. Decide entre graph_search (para entidades/relaciones), \"\n",
    "        \"vector_search (para pasajes textuales) o hybrid_search (para combinar). \"\n",
    "        \"Responde citando hechos claros y di si falta contexto.\"\n",
    "    )\n",
    "\n",
    "    agent = create_react_agent(\n",
    "        model=llm,\n",
    "        tools=tools,\n",
    "        prompt=system_prompt,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562727ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index, vec_index, composed = build_indices()\n",
    "# Registrar tools\n",
    "tools = build_tools(kg_index, vec_index, composed)\n",
    "# Crear agente\n",
    "agent = build_agent(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae94c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54538d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de pregunta:\n",
    "questions = [\n",
    "    \"¿Qué problema resuelve el mecanismo de Multi-Head Attention y por qué es útil?\",\n",
    "    \"¿Cómo se calcula el scaled dot-product attention?\",\n",
    "    \"¿Qué ventajas ofrece el Transformer frente a modelos recurrentes en el paper? Usa un vector search para informarte.\",\n",
    "    \"¿Qué ventajas ofrece el Transformer frente a modelos recurrentes en el paper? Usa un graph search para informarte.\",\n",
    "    \"¿Qué ventajas ofrece el Transformer frente a modelos recurrentes en el paper? Usa un hybrid search para informarte.\",\n",
    "]\n",
    "for question in questions:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Q:\", question)\n",
    "    result = agent.invoke({\"messages\": [(\"user\", question)]})\n",
    "    print(\"A:\", [result[\"messages\"][-1].content] if result[\"messages\"] else \"<sin respuesta>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931b314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
